{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yRIhS6lOTYX",
        "outputId": "961fdbff-9f0e-483c-b49e-b7a70922acba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets==3.1.0\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets==3.1.0)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (4.66.6)\n",
            "Collecting xxhash (from datasets==3.1.0)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets==3.1.0)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets==3.1.0)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (0.26.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets==3.1.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==3.1.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==3.1.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==3.1.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==3.1.0) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.1.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.1.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.1.0) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.1.0) (1.17.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets==3.1.0\n",
        "#load_dataset sometimes hangs on a higher version\n",
        "!pip install transformers torch evaluate tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JifsBqXxmtqm"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OjX3Y-kCzdpE"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# we set up some seeds so that we can reproduce results\n",
        "seed = 123\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo1A_mHu28Tp"
      },
      "source": [
        "# Step 1: Load and parse data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vF7FfaFP1lBn",
        "outputId": "7d4178b8-11fa-48e5-a118-fb2fca7d4260"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eMoGcjRgMk1E"
      },
      "outputs": [],
      "source": [
        "# Change train.json / dev.json to the appropriate filepaths =====\n",
        "def load_data():\n",
        "    data_files = {\"train\": \"/content/drive/My Drive/Colab Notebooks/all_train.json\", \"dev\": \"/content/drive/My Drive/Colab Notebooks/all_dev.json\"}\n",
        "    dataset = load_dataset('json', data_files=data_files)\n",
        "    train = dataset[\"train\"]\n",
        "    validation = dataset[\"dev\"]\n",
        "    return train, validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HHUhzzEE9Hdo"
      },
      "outputs": [],
      "source": [
        "class QADataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = 512\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.data[idx]\n",
        "        question = data[\"questions\"][0][\"input_text\"]\n",
        "        context = data[\"contexts\"]\n",
        "        answer = data[\"answers\"][0]\n",
        "        ans_start = answer['span_start']\n",
        "        ans_end = answer['span_end']\n",
        "        type_mapping = {\"short\": 1, \"no_answer\": 0}\n",
        "        ans_type = type_mapping.get(answer.get(\"input_text\", \"no_answer\"), 0)\n",
        "\n",
        "        # encode data\n",
        "        encoded_data = self.tokenizer(question,\n",
        "                                 context,\n",
        "                                 add_special_tokens=True,\n",
        "                                 max_length=self.max_len,\n",
        "                                 padding='max_length',\n",
        "                                 truncation=True,\n",
        "                                 return_attention_mask=True,\n",
        "                                 return_offsets_mapping=True,\n",
        "                                 return_tensors=\"pt\")\n",
        "\n",
        "        offsets = encoded_data.offset_mapping[0].tolist()\n",
        "        start_token = 0\n",
        "        end_token = 0\n",
        "        if ans_type != 0 and ans_start != -1 and ans_end != -1:\n",
        "            char_start = ans_start\n",
        "            char_end = ans_end\n",
        "            start_token = -1\n",
        "            end_token = -1\n",
        "            for i, (start, end) in enumerate(offsets):\n",
        "                if start == 0 and end == 0:\n",
        "                    continue\n",
        "                if start_token == -1 and start <= char_start < end:\n",
        "                    start_token = i\n",
        "                if end_token == -1 and start <= char_end <= end:\n",
        "                    end_token = i\n",
        "                # if both tokens are found no need to continue searching\n",
        "                if start_token != -1 and end_token != -1:\n",
        "                    break\n",
        "            if start_token == -1 or end_token == -1:\n",
        "                start_token = 0\n",
        "                end_token = 0\n",
        "        # print(\"start token:\", start_token)\n",
        "        # print(\"end token:\", end_token)\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoded_data[\"input_ids\"].squeeze(),\n",
        "            'attention_mask': encoded_data[\"attention_mask\"].squeeze(),\n",
        "            'start_positions': torch.tensor(start_token, dtype=torch.long),\n",
        "            'end_positions': torch.tensor(end_token, dtype=torch.long),\n",
        "            'ans_type': torch.tensor(ans_type, dtype=torch.long),\n",
        "            'offset_mapping': encoded_data[\"offset_mapping\"].squeeze(),\n",
        "            'context': context\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "go7rZOZc3_Ox"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def preprocess_and_tokenize(data, tokenizer):\n",
        "    dataset = QADataset(data, tokenizer)\n",
        "    batch_size = 32\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX8mc0574ZD_"
      },
      "source": [
        "# Step 2: Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "gJOgVaQtwRgj",
        "outputId": "1f61812c-f137-4dc4-f804-3badce1932ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nSome options for BERT model that can be run in colab:\\n\\n\"distilbert-base-uncased\",\\n\"distilbert-base-uncased-distilled-squad\",\\n\"distilbert-base-cased\",\\n\"distilbert-base-cased-distilled-squad\",\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "\"\"\"\n",
        "Some options for BERT model that can be run in colab:\n",
        "\n",
        "\"distilbert-base-uncased\",\n",
        "\"distilbert-base-uncased-distilled-squad\",\n",
        "\"distilbert-base-cased\",\n",
        "\"distilbert-base-cased-distilled-squad\",\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3NRuhosAIgDH"
      },
      "outputs": [],
      "source": [
        "from transformers import DistilBertModel, DistilBertConfig, DistilBertPreTrainedModel\n",
        "import torch.nn as nn\n",
        "\n",
        "class DistilBertForQA(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DistilBertForQA, self).__init__()\n",
        "        self.model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "        self.start_outputs = torch.nn.Linear(self.model.config.hidden_size, 1)\n",
        "        self.end_outputs = torch.nn.Linear(self.model.config.hidden_size, 1)\n",
        "        self.type_outputs = torch.nn.Linear(self.model.config.hidden_size, 5)\n",
        "\n",
        "    def forward(self, input_ids, token_types=None, attention_mask=None, start_positions=None, end_positions=None, ans_types=None):\n",
        "        outputs = self.model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Extract logits\n",
        "        start_logits = self.start_outputs(outputs.last_hidden_state).squeeze(-1)\n",
        "        end_logits = self.end_outputs(outputs.last_hidden_state).squeeze(-1)\n",
        "        type_logits = self.type_outputs(outputs.last_hidden_state[:, 0, :])\n",
        "\n",
        "        return start_logits, end_logits, type_logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ix7u_GWo4abf"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "def load_model():\n",
        "    model = DistilBertForQA()\n",
        "    tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "    return model, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss(start_logits, end_logits, type_logits, start_positions, end_positions, ans_types):\n",
        "    start_loss = nn.CrossEntropyLoss()(start_logits, start_positions)\n",
        "    end_loss = nn.CrossEntropyLoss()(end_logits, end_positions)\n",
        "    type_loss = nn.CrossEntropyLoss()(type_logits, ans_types)\n",
        "    loss = start_loss + end_loss + type_loss\n",
        "    return loss"
      ],
      "metadata": {
        "id": "KteMcLwEyfGv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJiEIINLY-12"
      },
      "source": [
        "# Step 3 Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vnTWneBTZA3e"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "def train_loop(model, train_dataloader, validation_dataloader, optimizer, lr_scheduler, num_epochs, device):\n",
        "    model.to(device)\n",
        "    train_loss = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        curr_train_loss = 0\n",
        "        progress_bar = tqdm(range(len(train_dataloader)))\n",
        "        for batch in train_dataloader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            start_positions = batch[\"start_positions\"].to(device)\n",
        "            # print(\"start:\", start_positions)\n",
        "            end_positions = batch[\"end_positions\"].to(device)\n",
        "            # print(\"end:\", start_positions)\n",
        "            ans_types = batch['ans_type'].to(device)\n",
        "\n",
        "            # Calculate loss\n",
        "            start_logits, end_logits, type_logits = model(\n",
        "                      input_ids=input_ids,\n",
        "                      attention_mask=attention_mask,\n",
        "                      start_positions=start_positions,\n",
        "                      end_positions=end_positions,\n",
        "                      ans_types=ans_types)\n",
        "            loss = get_loss(\n",
        "                start_logits,\n",
        "                end_logits,\n",
        "                type_logits,\n",
        "                start_positions,\n",
        "                end_positions,\n",
        "                ans_types)\n",
        "\n",
        "            curr_train_loss += loss.item()\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            lr_scheduler.step()\n",
        "\n",
        "            progress_bar.update(1)\n",
        "\n",
        "        train_loss.append(curr_train_loss / len(train_dataloader))\n",
        "        print(f\"Epoch {epoch+1} training loss: {train_loss[-1]}\")\n",
        "\n",
        "    return train_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4 Eval"
      ],
      "metadata": {
        "id": "X17NrNv-7xjg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "xW1b8ceMoE4z"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def eval_loop(model, validation_dataloader, device):\n",
        "    model.eval()\n",
        "    total_precision = 0\n",
        "    total_recall = 0\n",
        "    total_f1 = 0\n",
        "    span_preds = []\n",
        "    span_trues = []\n",
        "    num_batch = len(validation_dataloader)\n",
        "    with torch.no_grad():\n",
        "        for batch in validation_dataloader:\n",
        "            inputs = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            start_logits, end_logits, type_logits = model(inputs, attention_mask=attention_mask)\n",
        "\n",
        "            span_start_trues = batch['start_positions'].to(device)\n",
        "            span_end_trues = batch['end_positions'].to(device)\n",
        "            ans_type_trues = batch['ans_type'].to(device)\n",
        "\n",
        "            batch_size = start_logits.size(0)\n",
        "            curr_precision = 0\n",
        "            curr_recall = 0\n",
        "            curr_f1 = 0\n",
        "\n",
        "            for i in range(batch_size):\n",
        "                start_pred = torch.argmax(start_logits[i])\n",
        "                end_pred = torch.argmax(end_logits[i])\n",
        "                type_pred = torch.argmax(type_logits[i])\n",
        "                start_true = span_start_trues[i].item()\n",
        "                end_true = span_end_trues[i].item()\n",
        "                type_true = ans_type_trues[i].item()\n",
        "\n",
        "                index_pred = inputs[i][start_pred:end_pred + 1]\n",
        "                index_true = inputs[i][start_true:end_true + 1]\n",
        "                counter_pred = Counter(tokenizer.convert_ids_to_tokens(index_pred))\n",
        "                counter_true = Counter(tokenizer.convert_ids_to_tokens(index_true))\n",
        "                true_positive = sum((counter_pred & counter_true).values())\n",
        "                false_positive = sum((counter_pred - counter_true).values())\n",
        "                false_negative = sum((counter_true - counter_pred).values())\n",
        "\n",
        "                if true_positive + false_positive != 0:\n",
        "                    curr_precision += true_positive / (true_positive + false_positive)\n",
        "                if true_positive + false_negative != 0:\n",
        "                    curr_recall += true_positive / (true_positive + false_negative)\n",
        "                if curr_precision + curr_recall != 0:\n",
        "                    curr_f1 += 2 * (curr_precision * curr_recall) / (curr_precision + curr_recall)\n",
        "\n",
        "            total_precision += curr_precision / batch_size\n",
        "            total_recall += curr_recall / batch_size\n",
        "            total_f1 += curr_f1 / batch_size\n",
        "\n",
        "    return total_precision / num_batch, total_recall / num_batch, total_f1 / num_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqYSgjUk39V6"
      },
      "source": [
        "# Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185,
          "referenced_widgets": [
            "53a87a444a4641089c74e25841387361",
            "4d6a6acdc1b74ab7a0c1f3e1b590620b",
            "ce272675c40648d3aa64134f169554ac",
            "f1f5a8ee5317489981db8ae50cf4590f",
            "7ff75c2f409342ea882bf7f5de978a54",
            "44cfe08070fd4a58908c56349ce98039",
            "19e714bd53614121a96bc698532d8b66",
            "c11f7e1c6bde4641a84654f918568541",
            "44aa8a4464134c30a5ff4e4d8d61c6c6",
            "c4b1190f7f01482f9557815b2d8da027",
            "560b5e1bf7f440e6915af3a1a6d9e8fe",
            "b02aa0725b184181886f103f2bc4987a",
            "228badf14fde47178fd9c2e7bcd92faf",
            "6502752e9a204b659a36d064016ddc7a",
            "be65e0464b27442fbbd3a6cfcc9ddffe",
            "13b8bc9a8db14223a1be4b1317a7c0d0",
            "20aefffab252406eba5d7233c0724159",
            "d62620ad33794165bca09fe2d81c2b22",
            "6d4aadb3a26645b1ba95406da8c2741d",
            "f1edc7b70b424546839e6d55deb19d1a",
            "bcc38e8124a648cfa0c6f7e1bdcfb564",
            "8ee290f58217441f8d905b28dd05ffb3"
          ]
        },
        "id": "KS9ZcP-umJLN",
        "outputId": "e14b8b65-5fb5-4196-8ee4-fb56b29da368"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/871 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53a87a444a4641089c74e25841387361"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 training loss: 4.122598172602779\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/871 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b02aa0725b184181886f103f2bc4987a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 training loss: 2.3576733873030076\n",
            "Overall TRAIN LOSS:  [4.122598172602779, 2.3576733873030076]\n",
            "PRECISION:  0.6798551828243032\n",
            "RECALL:  0.7082178310981581\n",
            "F1-SCORE:  11.32230496113687\n"
          ]
        }
      ],
      "source": [
        "from transformers import get_scheduler\n",
        "from torch.optim import AdamW\n",
        "\n",
        "def main():\n",
        "\n",
        "  '''Here's the basic structure of the main block -- feel free to add or\n",
        "  remove parameters/helper functions as you see fit, but all steps here are\n",
        "  needed and we expect to see precision, recall, and f1 scores printed out'''\n",
        "  global model, tokenizer, validation_dataloader, device\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  batch_size = 32\n",
        "  num_epochs = 2\n",
        "\n",
        "  model, tokenizer = load_model()\n",
        "  model.to(device)\n",
        "  train, validation = load_data()\n",
        "\n",
        "  train_dataloader = preprocess_and_tokenize(train, tokenizer)\n",
        "  validation_dataloader = preprocess_and_tokenize(validation, tokenizer)\n",
        "\n",
        "  optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "  lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=50,\n",
        "    num_training_steps=len(train_dataloader) * num_epochs\n",
        "  )\n",
        "\n",
        "  train_loss = train_loop(\n",
        "      model,\n",
        "      train_dataloader,\n",
        "      validation_dataloader,\n",
        "      optimizer,\n",
        "      lr_scheduler,\n",
        "      num_epochs,\n",
        "      device)\n",
        "  print(\"Overall TRAIN LOSS: \", train_loss)\n",
        "\n",
        "  precision, recall, f1_score  = eval_loop(\n",
        "            model=model,\n",
        "            validation_dataloader=validation_dataloader,\n",
        "            device=device)\n",
        "\n",
        "  print(\"PRECISION: \", precision)\n",
        "  print(\"RECALL: \", recall)\n",
        "  print(\"F1-SCORE: \", f1_score)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BkOnHZpABWF"
      },
      "outputs": [],
      "source": [
        "from transformers import get_scheduler\n",
        "from torch.optim import AdamW\n",
        "\n",
        "def log():\n",
        "\n",
        "  '''Here's the basic structure of the main block -- feel free to add or\n",
        "  remove parameters/helper functions as you see fit, but all steps here are\n",
        "  needed and we expect to see precision, recall, and f1 scores printed out'''\n",
        "\n",
        "  global model, tokenizer, validation_dataloader, device\n",
        "  precision, recall, f1_score  = eval_loop(\n",
        "            model=model,\n",
        "            validation_dataloader=validation_dataloader,\n",
        "            device=device)\n",
        "\n",
        "  print(\"PRECISION: \", precision)\n",
        "  print(\"RECALL: \", recall)\n",
        "  print(\"F1-SCORE: \", f1_score)\n",
        "\n",
        "log()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "53a87a444a4641089c74e25841387361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d6a6acdc1b74ab7a0c1f3e1b590620b",
              "IPY_MODEL_ce272675c40648d3aa64134f169554ac",
              "IPY_MODEL_f1f5a8ee5317489981db8ae50cf4590f"
            ],
            "layout": "IPY_MODEL_7ff75c2f409342ea882bf7f5de978a54"
          }
        },
        "4d6a6acdc1b74ab7a0c1f3e1b590620b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44cfe08070fd4a58908c56349ce98039",
            "placeholder": "​",
            "style": "IPY_MODEL_19e714bd53614121a96bc698532d8b66",
            "value": "100%"
          }
        },
        "ce272675c40648d3aa64134f169554ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c11f7e1c6bde4641a84654f918568541",
            "max": 871,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_44aa8a4464134c30a5ff4e4d8d61c6c6",
            "value": 871
          }
        },
        "f1f5a8ee5317489981db8ae50cf4590f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4b1190f7f01482f9557815b2d8da027",
            "placeholder": "​",
            "style": "IPY_MODEL_560b5e1bf7f440e6915af3a1a6d9e8fe",
            "value": " 871/871 [22:07&lt;00:00,  1.51s/it]"
          }
        },
        "7ff75c2f409342ea882bf7f5de978a54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44cfe08070fd4a58908c56349ce98039": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19e714bd53614121a96bc698532d8b66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c11f7e1c6bde4641a84654f918568541": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44aa8a4464134c30a5ff4e4d8d61c6c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4b1190f7f01482f9557815b2d8da027": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "560b5e1bf7f440e6915af3a1a6d9e8fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b02aa0725b184181886f103f2bc4987a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_228badf14fde47178fd9c2e7bcd92faf",
              "IPY_MODEL_6502752e9a204b659a36d064016ddc7a",
              "IPY_MODEL_be65e0464b27442fbbd3a6cfcc9ddffe"
            ],
            "layout": "IPY_MODEL_13b8bc9a8db14223a1be4b1317a7c0d0"
          }
        },
        "228badf14fde47178fd9c2e7bcd92faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20aefffab252406eba5d7233c0724159",
            "placeholder": "​",
            "style": "IPY_MODEL_d62620ad33794165bca09fe2d81c2b22",
            "value": "100%"
          }
        },
        "6502752e9a204b659a36d064016ddc7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d4aadb3a26645b1ba95406da8c2741d",
            "max": 871,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1edc7b70b424546839e6d55deb19d1a",
            "value": 871
          }
        },
        "be65e0464b27442fbbd3a6cfcc9ddffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcc38e8124a648cfa0c6f7e1bdcfb564",
            "placeholder": "​",
            "style": "IPY_MODEL_8ee290f58217441f8d905b28dd05ffb3",
            "value": " 871/871 [22:12&lt;00:00,  1.51s/it]"
          }
        },
        "13b8bc9a8db14223a1be4b1317a7c0d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20aefffab252406eba5d7233c0724159": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d62620ad33794165bca09fe2d81c2b22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d4aadb3a26645b1ba95406da8c2741d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1edc7b70b424546839e6d55deb19d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bcc38e8124a648cfa0c6f7e1bdcfb564": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ee290f58217441f8d905b28dd05ffb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}